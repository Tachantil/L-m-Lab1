ТОП-5 позитивних слів:
[('excel', 10), ('marvel', 8), ('enjoy', 7), ('prefer', 7), ('opinion', 6)]

ТОП-5 негативних слів:
[('critic', 8), ('irrit', 8), ('opinion', 7), ('hate', 7), ('neg', 6)]

Аналіз:
Слово "opinion" зустрічається в обох категоріях, що може збивати модель.
Деякі слова є типовими маркерами емоцій ("excel", "critic", "hate").

Точність моделі: 74.3%

Звіт про класифікацію:
Метрика	    Клас 0 (негативні)	    Клас 1 (позитивні)
Precision	    0.73	                0.95
Recall	        1.00	                0.19
F1-score	    0.84	                0.32

Вплив параметра C (регуляризація)
Зі збільшенням значення C від 0.001 до 1000 спостерігалося покращення точності.
Найкраща точність: C = 10, де точність становила близько 77%, а F1-score для позитивного класу зріс до 0.44.
Висновок: Збалансоване значення C = 10 знижує регуляризацію, дозволяючи моделі краще вчитися.

Вплив max_iter (кількість ітерацій)
Тестування при max_iter = 100, 200, 300, 500 показало, що збільшення ітерацій майже не вплинуло на якість моделі.
Висновок: Значення max_iter=300 є оптимальним. Подальше збільшення не покращує результат, оскільки модель вже збігається.

Вплив solver (метод оптимізації)
liblinear, lbfgs та saga дали схожі результати.
Найстабільніший — liblinear через малий розмір текстових даних.

Вплив балансування класів
Додавання class_weight='balanced' збільшило Recall класу 1 до 0.72, підвищивши F1-score до 0.62.
Однак точність трохи знизилася до 70%, оскільки модель почала генерувати більше помилкових спрацьовувань на позитивний клас.

ВИСНОВКИ:
Основна проблема: Низький Recall класу 1 через дисбаланс вибірки.
Покращення, які спрацювали: регуляризація з C = 10. Додавання class_weight='balanced' суттєво підвищило Recall позитивного класу.
Тестування різних solver підтвердило, що liblinear — найстабільніший варіант.